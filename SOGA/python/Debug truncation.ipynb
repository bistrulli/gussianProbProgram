{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sexual-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussianmix import GaussianMix\n",
    "from soga import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alike-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "def debug(func):\n",
    "    \"\"\"Print the function signature and return value\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_debug(*args, **kwargs):\n",
    "        args_repr = [repr(a) for a in args]                      # 1\n",
    "        kwargs_repr = [f\"{k}={v!r}\" for k, v in kwargs.items()]  # 2\n",
    "        signature = \", \".join(args_repr + kwargs_repr)           # 3\n",
    "        print(f\"Calling {func.__name__}({signature})\\n\")\n",
    "        value = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__!r} returned {value!r}\\n\")           # 4\n",
    "        return value\n",
    "    return wrapper_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "together-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sympy import *\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import multivariate_normal as mvnorm\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def negate(trunc):\n",
    "    if '<' in trunc:\n",
    "        if '<=' in trunc:\n",
    "            trunc = trunc.replace('<=', '>')\n",
    "        else:\n",
    "            trunc = trunc.replace('<', '>=')\n",
    "    elif '>' in trunc:\n",
    "        if '>=' in trunc:\n",
    "            trunc = trunc.replace('>=', '<')\n",
    "        else:\n",
    "            trunc = trunc.replace('>', '<=')\n",
    "    elif '==' in trunc:\n",
    "        trunc = trunc.replace('==', '!=')\n",
    "    elif '!=' in turnc:\n",
    "        trunc = trunc.replace('!=', '==')\n",
    "    return trunc\n",
    "  \n",
    "def truncate(dist, trunc):\n",
    "    \"\"\" Given a distribution dist computes its truncation to trunc\"\"\"\n",
    "    if trunc == 'true':\n",
    "        return 1., dist\n",
    "    elif trunc == 'false':\n",
    "        return 0., dist\n",
    "    else:\n",
    "        d = len(dist.var_list)\n",
    "        # creates an augmented distribution with new variables appearing in aux_trunc (needed when gm(...) is involved)\n",
    "        aux_dist, aux_trunc = extract_aux(dist, trunc)\n",
    "        # converts aux_trunc to symbolic\n",
    "        aux_trunc = sym_trunc(aux_trunc)\n",
    "        # iterates on the component and truncates each one of them storing the relative probabilities on trunc\n",
    "        new_dist = Dist(dist.var_list, GaussianMix([],[],[]))\n",
    "        new_pi = []\n",
    "        for k in range(aux_dist.gm.n_comp()):\n",
    "            comp = Dist(aux_dist.var_list, aux_dist.gm.comp(k))\n",
    "            p, mu, sigma = truncate_gaussian(comp, aux_trunc) \n",
    "            new_dist.gm.mu.append(mu[:d])\n",
    "            new_dist.gm.sigma.append(sigma[:d,:d])\n",
    "            new_pi.append(aux_dist.gm.pi[k]*p)\n",
    "        norm_factor = sum(np.array(new_pi))\n",
    "        if norm_factor > 0:\n",
    "            new_dist.gm.pi = list(np.array(new_pi)/norm_factor)\n",
    "        return norm_factor, new_dist\n",
    "\n",
    "\n",
    "def extract_aux(dist, trunc):\n",
    "    \"\"\"Parse trunc to check for any gm(pi, mu, sigma) variable and adds it to dist\"\"\"\n",
    "    groups = [m.group() for m in re.finditer('gm\\(.*?\\)', trunc)]\n",
    "    aux_dist = deepcopy(dist)\n",
    "    aux_trunc = trunc\n",
    "    for n_aux, group in enumerate(groups):\n",
    "        new_pi = []\n",
    "        new_mu = []\n",
    "        new_sigma = []\n",
    "        aux_name = 'aux{}'.format(n_aux)\n",
    "        aux_trunc = aux_trunc.replace(group, aux_name)\n",
    "        pi_list, mu_list, sigma_list = [eval(m.group()) for m in re.finditer('\\[.*?\\]', group)]\n",
    "        aux_dist.var_list.append(aux_name)\n",
    "        for k in range(aux_dist.gm.n_comp()):\n",
    "            for j in range(len(pi_list)):\n",
    "                new_pi.append(aux_dist.gm.pi[k]*pi_list[j])\n",
    "                new_mu.append(np.hstack((aux_dist.gm.mu[k], mu_list[j])))\n",
    "                old_sigma = aux_dist.gm.sigma[k]\n",
    "                d = len(old_sigma)\n",
    "                aux_sigma = np.zeros((d+1,d+1))\n",
    "                aux_sigma[:d,:d] = old_sigma\n",
    "                aux_sigma[-1,-1] = sigma_list[j]\n",
    "                new_sigma.append(aux_sigma)\n",
    "        aux_dist.gm = GaussianMix(new_pi, new_mu, new_sigma)\n",
    "    return aux_dist, aux_trunc\n",
    "\n",
    "def sym_trunc(trunc):\n",
    "    \"\"\" Returns a symbolic version of trunc \"\"\"\n",
    "    if '==' in trunc:\n",
    "        lhs, rhs = trunc.split('==')\n",
    "        trunc = Eq(sympify(lhs), sympify(rhs))\n",
    "        trunc = simplify_logic(trunc)\n",
    "    elif '!=' in trunc:\n",
    "        lhs, rhs = trunc.split('!=')\n",
    "        trunc = Ne(sympify(lhs), sympify(rhs))\n",
    "        trunc = simplify_logic(trunc)\n",
    "    else:\n",
    "        trunc = simplify_logic(sympify(trunc))\n",
    "    return trunc\n",
    " \n",
    "    \n",
    "def truncate_gaussian(dist, trunc):\n",
    "    \"\"\" Given a distribution dist whose gm is has a single component computes its truncation to trunc \"\"\"\n",
    "    mu = dist.gm.mu[0]\n",
    "    sigma = dist.gm.sigma[0]\n",
    "# substitutes deterministic values, if the truncation becomes true or false returns\n",
    "    trunc = substitute_deltas(mu, sigma, trunc)\n",
    "    if str(trunc) == 'False':\n",
    "        return 0, mu, sigma\n",
    "    if str(trunc) == 'True':\n",
    "        return 1, mu, sigma\n",
    "    if type(trunc) is Equality:\n",
    "        return 0, mu, sigma\n",
    "    if type(trunc) is Unequality:\n",
    "        return 1, mu, sigma\n",
    "# extracts the vector (a_1, a_2, ..., a_k) of the truncation and the extremes of the hyper-rectangle\n",
    "    alpha, c = extract_alpha(trunc, dist.var_list)\n",
    "# changes coordinates so that the line alpha*x = 0 is one of the axis\n",
    "    A = find_basis(alpha)\n",
    "    transl_mu = A.dot(mu)\n",
    "    transl_sigma = A.dot(sigma).dot(A.transpose())\n",
    "    #transl_sigma = matrix_check(transl_sigma) \n",
    "# finds the indices of the components that needs to be transformed\n",
    "    transl_alpha = np.zeros(len(transl_mu))\n",
    "    transl_alpha[0] = 1\n",
    "    indices = select_indices(transl_alpha, transl_sigma)\n",
    "# creates reduced vectors taking into account only the coordinates that need to be transformed\n",
    "    red_transl_alpha = reduce_indices(transl_alpha, indices)\n",
    "    red_transl_mu = reduce_indices(transl_mu, indices)\n",
    "    red_transl_sigma = reduce_indices(transl_sigma, indices) \n",
    "    #print('Calling control after reduction')\n",
    "    #red_transl_sigma = matrix_check(red_transl_sigma)\n",
    "# creates the hyper-rectangle to integrate on\n",
    "    a = np.ones(len(red_transl_alpha))*(-1.e10)\n",
    "    b = np.ones(len(red_transl_alpha))*(1.e10)\n",
    "    if type(trunc) is StrictGreaterThan or type(trunc) is GreaterThan:\n",
    "        a[0] = c/np.linalg.norm(alpha)\n",
    "    if type(trunc) is StrictLessThan or type(trunc) is LessThan:\n",
    "        b[0] = c/np.linalg.norm(alpha)    \n",
    "# compute moments in the transformed coordinates\n",
    "    new_P, new_red_transl_mu, new_red_transl_sigma = compute_moments(red_transl_mu, red_transl_sigma, a, b)\n",
    "    #print('Calling control after truncation')\n",
    "    #new_red_transl_sigma = matrix_check(new_red_transl_sigma)\n",
    "# recreates extended vectors\n",
    "    new_transl_mu = extend_indices(new_red_transl_mu, transl_mu, indices)\n",
    "    new_transl_sigma = extend_indices(new_red_transl_sigma, transl_sigma, indices)\n",
    "    #print('Calling control after extension')\n",
    "    #new_transl_sigma = matrix_check(new_transl_sigma)\n",
    "# goes back to older coordinates\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    new_mu = A_inv.dot(new_transl_mu)\n",
    "    new_sigma = A_inv.dot(new_transl_sigma).dot(A_inv.transpose())\n",
    "    #print('Calling control after translating back')\n",
    "    #new_transl_sigma = matrix_check(new_transl_sigma)\n",
    "    return new_P, new_mu, new_sigma\n",
    "    \n",
    "    \n",
    "def substitute_deltas(mu, sigma, trunc):\n",
    "    for i in range(len(sigma)):\n",
    "        if sigma[i,i] == 0:\n",
    "            trunc = trunc.subs({dist.var_list[i]:mu[i]})\n",
    "    trunc = simplify_logic(trunc) \n",
    "    return trunc\n",
    "\n",
    "\n",
    "def extract_alpha(trunc, var_name):\n",
    "    # saves the two parts of the inequality in poly_lhs and poly_rhs\n",
    "    poly_lhs = trunc.args[0]\n",
    "    poly_rhs = trunc.args[1]\n",
    "    # computes the constant, changing sign if needed, as if it is on the RHS\n",
    "    if poly_rhs.is_constant():\n",
    "        c = float(poly_rhs)\n",
    "    elif poly_lhs.is_constant():\n",
    "        c = -float(poly_lhs)\n",
    "    else:\n",
    "        c = 0  \n",
    "    # computes the coefficients of the variables, changing signs if needed, as if they are on the LHS and saves them (ordered as in var_name) to the vector alpha\n",
    "    coeff_dict = {var:0 for var in var_name}\n",
    "    for sym in poly_lhs.free_symbols:\n",
    "        coeff_dict[str(sym)] = float(Poly(poly_lhs).coeff_monomial(str(sym)))\n",
    "    for sym in poly_rhs.free_symbols:\n",
    "        coeff_dict[str(sym)] = -float(Poly(poly_rhs).coeff_monomial(str(sym)))\n",
    "    alpha = np.zeros(len(var_name))\n",
    "    for i, var in enumerate(var_name):\n",
    "        alpha[i] = coeff_dict[var]\n",
    "    return alpha, c\n",
    "\n",
    "def find_basis(alpha):\n",
    "    \"\"\"\n",
    "    Given alpha (vector of the truncation) returns a matrix A giving the change of variable necessary to make alpha one of the axis\n",
    "    \"\"\"\n",
    "    alpha = alpha/np.linalg.norm(alpha)\n",
    "    u, s, v = np.linalg.svd([alpha])\n",
    "    alpha1 = v[:,1:]\n",
    "    A = np.vstack((alpha.reshape(1,alpha.shape[0]), alpha1.transpose()))\n",
    "    return A\n",
    "\n",
    "\n",
    "def select_indices(alpha, sigma):\n",
    "    \"\"\"\n",
    "    Finds the indices of the components that needs to be transformed based on the vector representation of the truncation (alpha) and the covariance matrix (sigma)\n",
    "    \"\"\"\n",
    "    \n",
    "    def enlarge_set(index_set):\n",
    "        total_set = index_set\n",
    "        for i in index_set:\n",
    "            i_indices = list(np.where(sigma[i,:] != 0)[0])\n",
    "            total_set = list(set(total_set + i_indices))\n",
    "        return total_set\n",
    "    \n",
    "    init_set = list(np.where(alpha!=0)[0])\n",
    "    new_set = enlarge_set(init_set)\n",
    "    while set(init_set) != set(new_set):\n",
    "        init_set = new_set\n",
    "        new_set = enlarge_set(init_set)   \n",
    "    return np.sort(new_set)  \n",
    "\n",
    "def reduce_indices(vec, indices):\n",
    "    \"\"\"\n",
    "    Extracts subvector/submatrix indexed by indices\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vec = np.array(vec, dtype='float32')\n",
    "    except np.ComplexWarning:\n",
    "        print(vec)    \n",
    "    if len(vec.shape) == 1:\n",
    "        red_vec = deepcopy(vec[indices])\n",
    "    if len(vec.shape) == 2:\n",
    "        red_vec = deepcopy(vec[indices][:,indices])\n",
    "    return red_vec\n",
    "\n",
    "\n",
    "def extend_indices(red_vec, old_vec, indices):\n",
    "    \"\"\"\n",
    "    puts red_vec in the indices of old_vec\n",
    "    \"\"\"\n",
    "    red_vec = np.array(red_vec, dtype='float32')\n",
    "    old_vec = np.array(old_vec, dtype='float32')\n",
    "    if len(old_vec.shape) == 1:\n",
    "        for red_i, i in enumerate(indices):\n",
    "            old_vec[i] = red_vec[red_i]\n",
    "    if len(old_vec.shape) == 2:\n",
    "        for red_i, i in enumerate(indices):\n",
    "            for red_j, j in enumerate(indices):\n",
    "                old_vec[i,j] = old_vec[j,i] = red_vec[red_i,red_j]\n",
    "    return old_vec\n",
    "\n",
    "### compute moments functions\n",
    "\n",
    "def partitionfunc(n,k,l=0):\n",
    "    \"\"\"\n",
    "    n is the integer to partition, k is the length of partitions, l is the min partition element size\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        return\n",
    "    if k == 1:\n",
    "        if n >= l:\n",
    "            yield (n,)\n",
    "        return\n",
    "    for i in range(l,n+1):\n",
    "        for result in partitionfunc(n-i,k-1):\n",
    "            yield (i,)+result\n",
    "\n",
    "def _prob(mu, sigma, a, b):\n",
    "    \"\"\"\n",
    "    Computes the mass probability of the normal distribution with mean mu and covariance matrix sigma in the \n",
    "    hyper-rectangle [a,b].\n",
    "    Even for one-dimensional distributions, mu, sigma, a, b must be vectors.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    P = 0\n",
    "    for i_list in product(*[[0,1]]*n):\n",
    "        x = np.zeros(n)\n",
    "        for i, idx in enumerate(i_list):\n",
    "            if idx==0:\n",
    "                x[i] = a[i]\n",
    "            else:\n",
    "                x[i] = b[i]\n",
    "        p = mvnorm.cdf(x,mean=mu,cov=sigma,allow_singular=True)\n",
    "        if np.isnan(p):\n",
    "            new_x = list(x) + [0]\n",
    "            new_mu = list(mu) + [0]\n",
    "            new_sigma = list(sigma)\n",
    "            for i in range(len(sigma)):\n",
    "                new_sigma[i] = list(sigma[i]) + [0]\n",
    "            new_sigma.append([0]*(len(sigma)+1))\n",
    "            p = mvnorm.cdf(new_x, mean=new_mu, cov=new_sigma, allow_singular=True)\n",
    "        P = P + ((-1)**(n-sum(i_list)))*p\n",
    "    #P = norm.cdf(b[0], loc=mu[0], scale=sigma[0,0]) - norm.cdf(a[0], loc=mu[0], scale=sigma[0,0])\n",
    "    return P\n",
    "    \n",
    "\n",
    "def compute_lower_mom(mu, sigma, a, b, trunc_idx, trunc):\n",
    "    \"\"\"\n",
    "    Given a normal with mean mu and cov matrix sigma,  truncated to [a,b] (where a[i] = -inf and b[i] = inf except\n",
    "    for a[trunc_idx] (if trunc = low) or b[trunc_idx] (if trunc=up)), computes the first two orders moments of a \n",
    "    (n-1) dimensional normal distribution with mean \\tilde(mu), \\tilde(sigma) (as defined in Kan-Robotti).\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    c = np.delete(a, trunc_idx)\n",
    "    d = np.delete(b, trunc_idx)\n",
    "    # computes the new mean\n",
    "    if trunc == 'low':\n",
    "        muj = np.delete(mu, trunc_idx) + ((a[trunc_idx]-mu[trunc_idx])/sigma[trunc_idx, trunc_idx])*np.delete(sigma, trunc_idx, axis=0)[:,trunc_idx]\n",
    "    elif trunc == 'up':\n",
    "        muj = np.delete(mu, trunc_idx) + ((b[trunc_idx]-mu[trunc_idx])/sigma[trunc_idx, trunc_idx])*np.delete(sigma, trunc_idx, axis=0)[:,trunc_idx]\n",
    "    # computes the new covariance matrix\n",
    "    sigmaj = np.delete(sigma, trunc_idx, axis=0)\n",
    "    sigmaj = np.delete(sigmaj, trunc_idx, axis=1)\n",
    "    sigmaj = sigmaj - (1/sigma[trunc_idx, trunc_idx])*np.delete(sigma, trunc_idx, axis=0)[:,trunc_idx].reshape(len(sigma)-1,1) @         np.delete(sigma, trunc_idx, axis=1)[trunc_idx,:].reshape(1,len(sigma)-1)  \n",
    "    # saves the moments in a dictionary\n",
    "    dict_mom_lower = {}\n",
    "    for k in range(3):\n",
    "        for part in partitionfunc(k, n-1):\n",
    "            if sum(part) == 0:\n",
    "                dict_mom_lower[part] = 1\n",
    "            if sum(part) == 1:\n",
    "                idx = np.where(np.array(part) == 1)[0][0]\n",
    "                dict_mom_lower[part] = muj[idx]\n",
    "            if sum(part) == 2:\n",
    "                idx_list = np.where(np.array(part)!=0)[0]\n",
    "                if len(idx_list) == 2:\n",
    "                    idx1, idx2 = idx_list\n",
    "                    dict_mom_lower[part] = sigmaj[idx1, idx2] + muj[idx1]*muj[idx2]\n",
    "                elif len(idx_list) == 1:\n",
    "                    idx = idx_list[0]\n",
    "                    dict_mom_lower[part] = sigmaj[idx, idx] + muj[idx]**2\n",
    "    return dict_mom_lower\n",
    "\n",
    "\n",
    "def _compute_mom1(n, k, mu, sigma, a, b, trunc_idx, trunc, dict_mom):\n",
    "    c = np.zeros(n)\n",
    "    idx = np.where(np.array(k)==1)[0][0]\n",
    "    if trunc == 'low':\n",
    "        c[trunc_idx] = norm.pdf(a[trunc_idx], loc=mu[trunc_idx], scale=np.sqrt(sigma[trunc_idx,trunc_idx]))\n",
    "    elif trunc == 'up':\n",
    "        c[trunc_idx] = -norm.pdf(b[trunc_idx], loc=mu[trunc_idx], scale=np.sqrt(sigma[trunc_idx,trunc_idx]))\n",
    "    return mu[idx]*dict_mom[tuple(n*[0])] + np.array(k).dot(sigma).dot(c)           \n",
    "\n",
    "\n",
    "def _compute_mom2(n, k, mu, sigma, a, b, trunc_idx, trunc, dict_mom, dict_mom_lower):\n",
    "    c = np.zeros(n)\n",
    "    index_list = np.where(np.array(k)!=0)[0]\n",
    "    if len(index_list) == 2:\n",
    "        idxk, idxe = index_list\n",
    "        ek = np.zeros(n)\n",
    "        ek[idxk] = 1\n",
    "        e = np.zeros(n)\n",
    "        e[idxe] = 1\n",
    "        for i in range(n):\n",
    "            if i == idxk:\n",
    "                c[i] = dict_mom[tuple(n*[0])]\n",
    "            if i == trunc_idx:\n",
    "                if trunc == 'low':\n",
    "                    c[i] = c[i] + (a[i]**ek[i])*norm.pdf(a[i], loc=mu[i], scale=np.sqrt(sigma[i,i]))*dict_mom_lower[tuple(np.delete(ek,i))]\n",
    "                elif trunc == 'up':\n",
    "                    c[i] = c[i] - (b[i]**ek[i])*norm.pdf(b[i], loc=mu[i], scale=np.sqrt(sigma[i,i]))*dict_mom_lower[tuple(np.delete(ek,i))]\n",
    "        return mu[idxe]*dict_mom[tuple(ek)] + e.dot(sigma).dot(c)   \n",
    "    elif len(index_list) == 1:\n",
    "        idx = index_list[0]\n",
    "        e = np.zeros(n)\n",
    "        e[idx] = 1\n",
    "        for i in range(n):\n",
    "            if i == idx:\n",
    "                c[i] = dict_mom[tuple(n*[0])]\n",
    "            if i == trunc_idx:\n",
    "                if trunc == 'low':\n",
    "                    c[i] = c[i] + (a[i]**e[i])*norm.pdf(a[i], loc=mu[i], scale=np.sqrt(sigma[i,i]))*dict_mom_lower[tuple(np.delete(e,i))]\n",
    "                elif trunc == 'up':\n",
    "                    c[i] = c[i] - (b[i]**e[i])*norm.pdf(b[i], loc=mu[i], scale=np.sqrt(sigma[i,i]))*dict_mom_lower[tuple(np.delete(e,i))]\n",
    "        return mu[idx]*dict_mom[tuple(e)] + e.dot(sigma).dot(c)           \n",
    "\n",
    "def compute_moments(mu, sigma, a, b):\n",
    "    \"\"\"\n",
    "    Given a normal distribution with mean mu and covariance matrix sigma, truncated to [a,b], where all a_i=-np.inf and\n",
    "    all b_i=np.inf except at most one a_i or one b_i, computes exactly the mean and the covariance matrix of the \n",
    "    truncated distribution\n",
    "    \"\"\"        \n",
    "    a = np.array(a, dtype='float32')\n",
    "    b = np.array(b, dtype='float32')\n",
    "    n = len(a)   \n",
    "    # truncation in one dimension\n",
    "    if n==1:\n",
    "        new_P = norm.cdf(b[0], loc=mu[0], scale=np.sqrt(sigma[0,0])) - norm.cdf(a[0], loc=mu[0], scale=np.sqrt(sigma[0,0]))\n",
    "        new_mu, new_sigma = truncnorm.stats(loc=mu[0], scale=np.sqrt(sigma[0,0]), a=(a[0]-mu[0])/np.sqrt(sigma[0,0]), b=(b[0]-mu[0])/np.sqrt(sigma[0,0]), moments='mv')\n",
    "        new_mu = np.array([new_mu])\n",
    "        new_sigma = np.array([[new_sigma]])\n",
    "        return new_P, new_mu, new_sigma\n",
    "    # if in more dimensions applies Kan-Robotti formulas\n",
    "    # first determines if the truncation is 'low' (i.e. x > c) or 'up' (i.e. x < c)\n",
    "    trunc_idx = 0\n",
    "    if a[0] > -1.e10:\n",
    "        trunc = 'low'\n",
    "    else:\n",
    "        trunc = 'up'  \n",
    "    # returns the moments for the distribution of dimension n-1, in which the trunc_idx component has been removed\n",
    "    dict_mom_lower = compute_lower_mom(mu, sigma, a, b, trunc_idx, trunc)  \n",
    "    # computes first two order moments using the recurrence formulas of Kan-Robotti and stores them in a dictionary\n",
    "    dict_mom = {}\n",
    "    for k in range(3):\n",
    "        for part in partitionfunc(k, n): \n",
    "            if sum(part) == 0:\n",
    "                dict_mom[part] = _prob(mu, sigma, a, b)\n",
    "                if dict_mom[part] == 0:\n",
    "                    return 0, mu, sigma\n",
    "            if sum(part) == 1:\n",
    "                dict_mom[part] = _compute_mom1(n, part, mu, sigma, a, b, trunc_idx, trunc, dict_mom)\n",
    "            if sum(part) == 2:\n",
    "                dict_mom[part] = _compute_mom2(n, part, mu, sigma, a, b, trunc_idx, trunc, dict_mom, dict_mom_lower)              \n",
    "    # assembles the dictionaries result in new_P, new_mu, new_sigma\n",
    "    new_P = dict_mom[tuple(n*[0])]\n",
    "    new_mu = np.zeros(n)\n",
    "    new_sigma = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        e = np.zeros(n)\n",
    "        e[i] = 1\n",
    "        new_mu[i] = dict_mom[tuple(e)]/new_P\n",
    "        new_sigma[i,i] = dict_mom[tuple(2*e)]/new_P - (dict_mom[tuple(e)]/new_P)**2\n",
    "        for j in range(i):\n",
    "            f = np.zeros(n)\n",
    "            f[j] = 1\n",
    "            new_sigma[i,j] = new_sigma[j,i] = dict_mom[tuple(e+f)]/new_P - (dict_mom[tuple(e)]/new_P)*(dict_mom[tuple(f)]/new_P)\n",
    "    return new_P, new_mu, new_sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "protective-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Dist(['x'], GaussianMix([1.],[np.array([0.])],[np.array([[1.]])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abstract-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32635603071511887,\n",
       " pi: [0.44837160653205016, 0.32804464218912316, 0.22358375127882657] mu: [array([0.84492525]), array([1.05170279]), array([1.27406071])] sigma: [array([[0.40016629]]), array([[0.34825692]]), array([[0.30555952]])])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, dist = truncate(dist, 'x - gm([0.33,0.33,0.33],[0.15, 0.48, 0.81],[1/9, 1/9, 1/9]) > 0')\n",
    "p, dist.gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-accountability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
